{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import random\n",
    "import zipfile\n",
    "import io\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "\n",
    "import glob\n",
    "import imageio\n",
    "from six import BytesIO\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import display, Javascript\n",
    "from IPython.display import Image as IPyImage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOUNDING_BOXES_PATH = '../input/car-object-detection/data/train_solution_bounding_boxes (1).csv'\n",
    "TRAINING_IMAGES_PATH = '../input/car-object-detection/data/training_images'\n",
    "TESTING_IMAGES_PATH = '../input/car-object-detection/data/testing_images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_height = 380\n",
    "im_width = 676\n",
    "num_classes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes_df = pd.read_csv(BOUNDING_BOXES_PATH)\n",
    "bboxes_df.sort_values(by='image', inplace = True)\n",
    "bboxes_df.reset_index(drop = True, inplace = True)\n",
    "bboxes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{} train images with {} car bounding boxes.'.format(len(bboxes_df['image'].unique()), bboxes_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for simplicity we will use only the first object detected in each image\n",
    "gt_boxes_np = []\n",
    "for name,xmin,ymin,xmax,ymax in bboxes_df.drop_duplicates(subset='image', keep='first').values:\n",
    "    gt_boxes_np.append(np.array([[ymin/im_height, xmin/im_width, ymax/im_height, xmax/im_width]]))\n",
    "    \n",
    "# convert to list of tensor objects\n",
    "gt_boxes_tensors = []\n",
    "for gt_box in gt_boxes_np:\n",
    "    gt_boxes_tensors.append(tf.convert_to_tensor(gt_box,dtype = tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install object detection API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone --depth 1 https://github.com/tensorflow/models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd models/research/ && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def load_image_in_array(path):\n",
    "    img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
    "    image = Image.open(BytesIO(img_data))\n",
    "    im_width, im_height = image.size\n",
    "    return np.array(image.getdata()).reshape(\n",
    "        (im_height, im_width, 3)).astype(np.uint8)\n",
    "\n",
    "def plot_detections(image, bboxes, classes, scores, category_index, use_normalized_coordinates=True, min_score_thresh=0.8):\n",
    "    \"\"\" to vizualise images with bounding boxes\"\"\"\n",
    "    image_with_annotations = image.copy()\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(image_with_annotations,\n",
    "                                                       bboxes,\n",
    "                                                       classes,\n",
    "                                                       scores,\n",
    "                                                       category_index,\n",
    "                                                       use_normalized_coordinates=use_normalized_coordinates,\n",
    "                                                       min_score_thresh=min_score_thresh)\n",
    "    plt.imshow(image_with_annotations)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create category dictionary\n",
    "car_class_id = 1\n",
    "\n",
    "category_index = {car_class_id:{\n",
    "    'id':1,\n",
    "    'name':'car'\n",
    "}}\n",
    "category_index[car_class_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the 6 first images with their bounding boxes\n",
    "plt.figure(figsize = (30,15))\n",
    "for idx in range(6):\n",
    "    plt.subplot(2,3,idx + 1)\n",
    "    \n",
    "    filename = bboxes_df.image[idx]\n",
    "    filepath = TRAINING_IMAGES_PATH + '/' + filename\n",
    "    image_np = load_image_in_array(filepath)\n",
    "    \n",
    "    plot_detections(image_np,\n",
    "                gt_boxes_np[idx],\n",
    "                np.ones(shape=[gt_boxes_np[idx].shape[0]], dtype=np.int32),\n",
    "                np.array([1.0], dtype=np.float32), \n",
    "                category_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes_df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_images(folder_path, names, num_of_images = 20):\n",
    "    images_list = []\n",
    "    for i, im_name in enumerate(bboxes_df.image.unique()[0:num_of_images]):\n",
    "        IM_PATH = folder_path + '/'+ im_name\n",
    "        image = load_image_in_array(IM_PATH)\n",
    "        images_list.append(image)\n",
    "        print (i,'of', num_of_images, ':', im_name)\n",
    "    return images_list    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_images_for_training = 352\n",
    "train_images_np = load_train_images(TRAINING_IMAGES_PATH, gt_boxes_np, num_of_images_for_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the checkpoint and put it into models/research/object_detection/test_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz\n",
    "!tar -xf ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz\n",
    "!mv ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint models/research/object_detection/test_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILE_PATH = './models/research/object_detection/configs/tf2/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.config'\n",
    "CHECKPOINT_PATH = './models/research/object_detection/test_data/checkpoint/ckpt-0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load the config file and adjust some parameters\n",
    "\n",
    "config = config_util.get_configs_from_pipeline_file(CONFIG_FILE_PATH)\n",
    "model_config = config['model']\n",
    "model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config.ssd.num_classes = num_classes\n",
    "model_config.ssd.freeze_batchnorm = True\n",
    "model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_detection_model = model_builder.build(model_config = model_config, is_training = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RetinaNet has two prediction `heads` --- one for classification, the other for box regression.  We will\n",
    "# restore the box regression head but initialize the classification head from scratch\n",
    "\n",
    "tmp_box_predictor = tf.train.Checkpoint(\n",
    "    _base_tower_layers_for_heads=car_detection_model._box_predictor._base_tower_layers_for_heads,\n",
    "    _box_prediction_head=car_detection_model._box_predictor._box_prediction_head,\n",
    "    )\n",
    "tmp_model = tf.train.Checkpoint(\n",
    "          _feature_extractor=car_detection_model._feature_extractor,\n",
    "          _box_predictor=tmp_box_predictor)\n",
    "\n",
    "ckpt = tf.train.Checkpoint(model=tmp_model)\n",
    "ckpt.restore(CHECKPOINT_PATH).expect_partial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We run the model through a dummy image so that variables are created\n",
    "image, shapes = car_detection_model.preprocess(tf.zeros([1, im_height, im_width, 3]))\n",
    "prediction_dict = car_detection_model.predict(image, shapes)\n",
    "_ = car_detection_model.postprocess(prediction_dict, shapes)\n",
    "print('Weights restored!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a custom training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step_fn(model, optimizer, vars_to_fine_tune, image_tensors, gt_boxes_list, gt_classes_list):\n",
    "    \n",
    "    shapes = tf.constant(BATCH_SIZE * [[im_height, im_width, 3]], dtype=tf.int32)\n",
    "    model.provide_groundtruth(\n",
    "        groundtruth_boxes_list=gt_boxes_list,\n",
    "        groundtruth_classes_list=gt_classes_list)\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "      preprocessed_images = tf.concat([model.preprocess(image_tensor)[0]\n",
    "           for image_tensor in image_tensors], axis=0)\n",
    "      prediction_dict = model.predict(preprocessed_images, shapes)\n",
    "      losses_dict = model.loss(prediction_dict, shapes)\n",
    "      total_loss = losses_dict['Loss/localization_loss'] + losses_dict['Loss/classification_loss']\n",
    "      gradients = tape.gradient(total_loss, vars_to_fine_tune)\n",
    "      optimizer.apply_gradients(zip(gradients, vars_to_fine_tune))\n",
    "    \n",
    "    return total_loss \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select variables in top layers to fine-tune.\n",
    "trainable_variables = car_detection_model.trainable_variables\n",
    "to_fine_tune = []\n",
    "prefixes_to_train = [\n",
    "  'WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead',\n",
    "  'WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead']\n",
    "for var in trainable_variables:\n",
    "  if any([var.name.startswith(prefix) for prefix in prefixes_to_train]):\n",
    "    to_fine_tune.append(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE TENSOR OBJECT FOR TRAINING\n",
    "# for ground truth boxes\n",
    "gt_box_tensors = gt_boxes_tensors[:num_of_images_for_training]\n",
    "\n",
    "# for ground truth classes \n",
    "label_id_offset = 1\n",
    "gt_classes_one_hot_tensors = []\n",
    "for gt_box_np in gt_boxes_np:\n",
    "    zero_indexed_groundtruth_classes = tf.convert_to_tensor(np.ones(shape=[gt_box_np.shape[0]], dtype=np.int32) - label_id_offset)\n",
    "    gt_classes_one_hot_tensors.append(tf.one_hot(zero_indexed_groundtruth_classes, num_classes))\n",
    "\n",
    "# and for train images\n",
    "train_image_tensors = []\n",
    "for train_image_np in train_images_np:\n",
    "  train_image_tensors.append(tf.expand_dims(tf.convert_to_tensor(\n",
    "      train_image_np, dtype=tf.float32), axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "learning_rate = 0.01\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate = learning_rate, momentum = .9)\n",
    "num_of_batches = int(num_of_images_for_training / BATCH_SIZE)\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "print('start fine tuning')\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    epoch_avg_loss = 0\n",
    "    random_positions = list(range(num_of_images_for_training))\n",
    "    random.shuffle(random_positions)\n",
    "    batches_list = [random_positions[i:i+BATCH_SIZE-1] for i in range(0, len(random_positions), BATCH_SIZE-1)] \n",
    "    \n",
    "    for batch_pos in batches_list:\n",
    "        gt_boxes_list = [gt_box_tensors[key] for key in batch_pos]\n",
    "        gt_classes_list = [gt_classes_one_hot_tensors[key] for key in batch_pos]\n",
    "        image_tensors = [train_image_tensors[key] for key in batch_pos]\n",
    "\n",
    "        total_loss = train_step_fn(car_detection_model, optimizer, to_fine_tune, image_tensors, gt_boxes_list, gt_classes_list)\n",
    "        epoch_avg_loss += total_loss\n",
    "    epoch_avg_loss /= int(num_of_images_for_training / BATCH_SIZE)  \n",
    "    #if epoch%10 == 0:\n",
    "    print('epoch ' + str(epoch) + ' of ' + str(epochs) + ', loss=' +  str(epoch_avg_loss.numpy()),\n",
    "          ', epoch train time=',np.round(time.time() - start_time, 2),\n",
    "          'sec, estimated remaining time=', np.round((time.time() - start_time)*(epochs - epoch) / 60, 2),'mins',\n",
    "          flush=True)\n",
    "        \n",
    "print('finish fine tuning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def detect(input_tensor):\n",
    "    \n",
    "    expanded_tensor = tf.expand_dims(input_tensor,axis=0)\n",
    "    \n",
    "    preprocessed_image, shapes = car_detection_model.preprocess(expanded_tensor)\n",
    "    prediction_dict = car_detection_model.predict(preprocessed_image, shapes)\n",
    "    return car_detection_model.postprocess(prediction_dict, shapes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_IOU(gt_box, pred_box):\n",
    "    \n",
    "    # 1.get the coordinate of inters\n",
    "    ixmin = max(pred_box[0], gt_box[0])\n",
    "    ixmax = min(pred_box[2], gt_box[2])\n",
    "    iymin = max(pred_box[1], gt_box[1])\n",
    "    iymax = min(pred_box[3], gt_box[3])\n",
    "\n",
    "    iw = np.maximum(ixmax-ixmin+1., 0.)\n",
    "    ih = np.maximum(iymax-iymin+1., 0.)\n",
    "\n",
    "    # 2. calculate the area of inters\n",
    "    inters = iw*ih\n",
    "\n",
    "    # 3. calculate the area of union\n",
    "    uni = ((pred_box[2]-pred_box[0]+1.) * (pred_box[3]-pred_box[1]+1.) +\n",
    "           (gt_box[2] - gt_box[0] + 1.) * (gt_box[3] - gt_box[1] + 1.) -\n",
    "           inters)\n",
    "\n",
    "    # 4. calculate the overlaps between pred_box and gt_box\n",
    "    iou = inters / uni\n",
    "\n",
    "    return iou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_im = 150\n",
    "filename = bboxes_df.image[test_im]\n",
    "filepath = TESTING_IMAGES_PATH + '/' + 'vid_5_26800.jpg'\n",
    "test_image = load_image_in_array(filepath)\n",
    "\n",
    "input_tensor = tf.convert_to_tensor(test_image, dtype=tf.float32)\n",
    "detections = detect(input_tensor)\n",
    "\n",
    "plt.figure(figsize = (30,15))\n",
    "plot_detections(test_image, \n",
    "                detections['detection_boxes'][0].numpy(),\n",
    "                detections['detection_classes'][0].numpy().astype(np.uint32) + label_id_offset,\n",
    "                detections['detection_scores'][0].numpy(),\n",
    "                category_index,\n",
    "                True, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets calculate the IOU score for an image with known bounding boxes with a single car\n",
    "train_im = 5\n",
    "filename = bboxes_df.image[train_im]\n",
    "filepath = TRAINING_IMAGES_PATH + '/' + filename\n",
    "print('file:',filename)\n",
    "train_image = load_image_in_array(filepath)\n",
    "\n",
    "input_tensor = tf.convert_to_tensor(train_image, dtype=tf.float32)\n",
    "detections = detect(input_tensor)\n",
    "\n",
    "#plot detections\n",
    "plt.figure(figsize = (30,15))\n",
    "plot_detections(train_image, \n",
    "                detections['detection_boxes'][0].numpy(),\n",
    "                detections['detection_classes'][0].numpy().astype(np.uint32) + label_id_offset,\n",
    "                detections['detection_scores'][0].numpy(),\n",
    "                category_index,\n",
    "                True, 0.6)\n",
    "\n",
    "#calculate IOU\n",
    "detected_bb = detections['detection_boxes'][0].numpy()[0]\n",
    "gt_bb = np.array([bboxes_df.iloc[train_im].ymin/im_height, \n",
    "                   bboxes_df.iloc[train_im].xmin/im_width,\n",
    "                   bboxes_df.iloc[train_im].ymax/im_height,\n",
    "                   bboxes_df.iloc[train_im].xmax/im_width])\n",
    "IOU = get_IOU(detected_bb, gt_bb)\n",
    "print('IOU score: ', IOU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
